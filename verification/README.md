# Verification Module

This module provides tools for verifying Lean proofs generated by LLMs.

## Files

- `jsonl_verifier.py`: Core verification engine that generates Lean files and runs the Lean compiler
- `verify_individual.py`: Simplified interface for verifying individual dataset results
- `test_verifier.py`: Tests for the verification module

## Usage

### Verify Individual Dataset Result

Use `verify_individual.py` to verify a single result file:

```bash
python -m verification.verify_individual <result_file>
```

Example:
```bash
python -m verification.verify_individual results/gpt-4o/obfuscated_1/result_1.jsonl
```

The dataset name is automatically parsed from the file path (e.g., `obfuscated_1` from `results/gpt-4o/obfuscated_1/result_1.jsonl`).

### Use in Python Code

```python
from verification.verify_individual import verify_individual_dataset
from pathlib import Path

# Verify a single result file - dataset name is parsed automatically
stats = verify_individual_dataset(
    result_file=Path("results/gpt-4o/obfuscated_1/result_1.jsonl"),
    repo_folder="."  # Optional, defaults to "."
)

# Access results
print(f"Total: {stats['total']}")
print(f"Correct: {stats['correct']}")
print(f"Correct rate: {stats['correct_rate']*100:.2f}%")
print(f"Error IDs: {stats['error_ids']}")
print(f"Sorry IDs: {stats['sorry_ids']}")
print(f"Banned tactics: {stats['banned_tactics_usage']}")
```

### Return Value

`verify_individual_dataset` returns a dictionary with:
- `run`: Run number (extracted from result file)
- `total`: Total number of proofs
- `correct`: Number of correct proofs
- `incorrect`: Number of incorrect proofs
- `error_ids`: List of theorem IDs with verification errors
- `sorry_ids`: List of theorem IDs containing 'sorry'
- `banned_tactics_usage`: Dictionary mapping theorem IDs to lists of banned tactics used
- `banned_count`: Number of proofs using banned tactics
- `correct_rate`: Fraction of correct proofs (0.0 to 1.0)

## Integration with score_llm.py

The `score_llm.py` script uses `verify_individual_dataset` to simplify the verification process:

```python
from verification.verify_individual import verify_individual_dataset

# Verify a result file - dataset name parsed automatically from path
stats = verify_individual_dataset(result_file, repo_folder)

# Add timing information
stats["avg_time"] = avg_time

# Use stats for reporting
print(f"Correct rate: {stats['correct_rate']*100:.2f}%")
```

This eliminates the need to:
1. Manually parse dataset name from file path
2. Manually create generated_proofs files
3. Call verify_dataset directly
4. Calculate correct/incorrect counts
5. Handle error and sorry ID merging

All these operations are encapsulated in `verify_individual_dataset`.
