# -Obfuscated-PeanoBench

Large Language Models (LLMs) have demonstrated impressive capabilities in formal theorem proving, achieving high scores on benchmarks such as MiniF2F. However, it remains an open question whether these results stem from grounded mathematical reasoning or the memorization of training data (data contamination). This study investigates this distinction by benchmarking frontier LLMs (GPT-4o, Claude 3.5 Sonnet) on the Lean Natural Number Game (via the PeanoBench dataset).

We introduce a novel evaluation protocol involving semantics-preserving obfuscation, where axioms, types, and theorem names are systematically renamed to strip surface-level patterns while preserving the underlying logical structure. Unlike previous studies that focus on general code (LiveCodeBench), this research specifically targets the fragility of formal inductive reasoning. We hypothesize that performance will degrade significantly under obfuscation, indicating a reliance on syntactic memorization over logical construction. By quantifying this "robustness gap," this project aims to provide a rigorous metric for true mathematical understanding in neural theorem provers and highlights the limitations of current static benchmarks.
